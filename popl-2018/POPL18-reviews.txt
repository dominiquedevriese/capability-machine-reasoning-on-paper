POPL '18 Paper #2 Reviews and Comments
===========================================================================
Paper #24 Reasoning about a Capability Machine with Local Capabilities -
Provably Safe Stack and Return Pointer Management (without OS Support)


Review #24A
===========================================================================

Overall merit
-------------
3. Weak reject - will not argue against

Reviewer expertise
------------------
Y. Knowledgeable

Paper summary
-------------
Capability machines are processes that prevent attacks on control-flow correctness and local-state encapsulation with a hardware-level security model. This paper presents a formalization of a capability machine with local capabilities and proposes a novel calling convention for enforcing control-flow correctness and encapsulation of local state. The paper presents a formalization of a simple but representative capability machine, defines a novel calling convention that relies solely on local capabilities and does not require OS support. The authors present a novel Kripke logical relation for reasoning about programs on the capability machine and prove an analog of the standard fundamental theorem of logical relations. The authors introduce two novel technical ideas in the unary, step-indexed Kripke logical relation used to formulate the theorem. First, they model the natural continuation-passing style of assembly code using a single orthogonal closure. Second, they express local capabilities using a variant of Dreyer et al’s public and private future worlds. The authors demonstrate local-state encapsulation and control-flow correctness guarantees on a couple of examples in the presence of cross-component function pointers.

Strengths:
+ It is an interesting idea to use a calling convention with local capabilities to enforce security properties.
+ The solution involves an interesting formalism and the authors prove safety for it.
+ The authors demonstrate that their solution can handle a couple of complex examples.

Weaknesses:
- It seems the paper is written for quite a narrow and theoretical audience.
- Especially for those not familiar with issues surrounding capability machines, the paper could use better motivation for why this new calling convention is useful.
Lau: To our knowledge, there exists no established calling conventions for capability machines - in fact capability machines come in many varieties and calling conventions will differ based on the available types of capabilities. For this work, we have assumed local capabilities which, to our knowledge, is only found in CHERI. CHERI uses the a CHERI specific call instruction to handle calls. We developed a calling convention that does not use a special call instruction and only rely on the security provided by capabilities. We designed a calling convention that ensures local-state encapsulation and well-bracketed control-flow because these are properties that we expect in a high-level language (this is also touched upon in the introduction of the paper).

It is not clear what the improvement is over existing work. It would be useful to make this more concrete via examples.
- There is little discussion of the practicality of this approach.
Lau: We have do have a discussion about practicality, namely the discussion about the memory clearing instruction. (As it turns out, such an instruction is not feasible and the calling convention will therefore probably not see any use. That said, this also highlight a huge limitation with local capabilities, namely that eventhough they limit the places a capability can be stored, there will still be a significantoverhead attached to searching through this space.)

I can get behind the general motivation for capability machines and found the proposed solution to be interesting and thorough. As someone who has not worked with capability machines, however, I found this paper difficult to read for the amount of background knowledge it assumes. It may be an issue of presentation, but I was not sure what were the main challenges that this paper addresses, what the key insights were, and how this work improves upon existing work. I would have also liked to see more discussion of the practicality of the approach.
Lau: I am  not sure how to address this. We could try to describe an example run, but that seems very rudamentary.

Comments for author
-------------------
High-level comments:
- It would be useful to provide more context and background about capability machines, local capabilities, and the shortcomings of existing work on capability machines.
- It would be useful to introduce the examples from Section 5 earlier in the paper, as part of the motivation.
Lau: This may be true, but it might also introduce confusing elements because the examples use things that are introduced rather late in the paper.

- For the examples in Section 5, it would be useful to provide more high-level description and intuition before going into the details of the examples.
Lau: experience shows that a high-level description (at least in the form of an ML like program) is a bad idea, because everyone seems to have their own idea about what the exact ML semantics are.

Lower-level comments: 
- “About” should be capitalized in the title.
Lau: fixed

Questions:
- What are the performance implications of using local capabilities, as opposed to regular capabilities?
Lau: This question is not quite clear to me. To my knowledge, the local capabilities themeselves do not give a significant bit, because the only time they affect the semantics is in the store instruction where the locality bit needs to be inspected. If the question is with regard to the calling convention, then there is one huge slow down (as discussed in the discussion section), namely the memory clearing needed before each call.


Review #24B
===========================================================================

Overall merit
-------------
5. Accept - will argue for

Reviewer expertise
------------------
Y. Knowledgeable

Paper summary
-------------
The paper presents a formal capability machine inspired by some
experimental proposals for capability-based hardware such as the
M-Machine and CHERI.  It gives a set of calling conventions that
ensure security regardless of the behavior of adversary programs.  And
it gives a formal model (based on prior work by Dreyer et al.) for
proving that it works.  Proofs are claimed, but did not fit into the
paper.

This is a nice piece of work; it seems solid and it was enjoyable to
read.  Everything seems plausible, but I have not acquired to the
supplementary material and checked the proofs.

Comments for author
-------------------
I don't actually have much to suggest by way of improvement:

On page 5, there is a line of what appears to be stray text.
Lau: Fixed

In figure 6, a little more explanation would not go awry.
Particularly why none of the cases but E make any claims about a.
Lau: I have not addressed this, but I feel like it in general terms is described what the value relation do. We could of course come back to it later and point out some details like the address that is only "relevant" for the enter capability. 

TODO: On page 15, the third paragraph ("For capabilities with read
permission...") I didn't understand at all.
 


Review #24C
===========================================================================

Overall merit
-------------
5. Accept - will argue for

Reviewer expertise
------------------
Y. Knowledgeable

Paper summary
-------------
A viewpoint-neutral summary of the paper's content

This paper describes a formal model of a capability-based CPU, and
claims formal proof of a number of security properties related to that
model, notably control flow correctness and a form of capability
confinement.  After a general introduction, section 2 introduces the
machine model, based on CHERI and the M-Machine, and then section 3
describes how that machine can support safe control flow to and from
untrusted adversary code. Section 4 introduces the core of the
formalism, a logical relation that captures which memory
configurations are (or are not) safe - that is, which do not breach a
program's invariants.  Section 5 presents some short examples and
sketches their proofs, and section 6 discusses details of both
implementation and formalisation. Section 7 places this work in the
context of related research; the paper offers no conclusion. 

A list of major points for and against accepting the paper.

+ important result
+ result appears correct
+ easy to follow for relative non-expert, good informal introduction
- no claim of mathematical proof
Lau: it is a stretch to say that there is no mathematical proof (they are there in the technical appendix). That said, it is my understanding that this is to be taken as there is no mechanical proof (as pointed out in the explanation further below). 
- no claim of an artifact 


More detailed explanation of these points and justification for your
recommendation.

This paper offers an important result in capability-based models for
security. Just as e.g. typed assembly language brings the benefits of
static type systems down to the hardware level, this work aims to
bring the benefits of recent research in language-level capability
security to capability based hardware. In this setting, the key
results, that e.g. control flow structure is preserved, and that
untrusted attacker code can only affect particular memory regions is
both novel and significant.  While it seems unlikely this work will be
directly applicable to existing production systems on commodity
hardware, it is certainly very valuable in guiding the design of
future capability-based hardware.

As far as I can tell, the result appears correct (although see points
against below). The formal techniques, while relatively novel, are
becoming accepted in this kind of work (particularly Devrise et al,
2016). That is, although they are complex, there seems no obvious
reason why they are not correct: the results accord with intuition.
Lau: It may be worth to point out that eventhough a logical relation is used in Devriese et al, it is not the same. Some novel contributions were necessary to make the LR work for this setting (see "Public/private future worlds" in the discussion section).

This impression is reinforced by the careful explanations in the
paper, particularly in section 3, but also in section 6, which mean
this paper is quite approachable by non-experts. 

The main points against this work are that it is supported by a
90-page technical appendix containing only a manual proof, and the
paper offers no reproducible artifact --- either as a full mechanical
proof, or e.g. even a model of the capability machine in something
like PLT Redex.  Ultimately, the question as to whether this is
sufficient validation must be considered by the programme committee as
a whole.
 
A list of any explicit questions you would like to have answered by
the authors' rebuttal.

no questions necessary for rebuttal;
some questions below may be of use for revisions

Comments for author
-------------------

* please give you machine a name, even if just "LCM" - that will make
  discussing it easier.
Lau: I am still reluctant to do this, as I see the reasoning principles as the centerpiece rather than the machine itself. I do, however, see that it is easier to discuss a machine with a name.

* I'm old, so I'd appreciate a brief discussion LCM's relationship
  with the capability hardware I (and perhaps other older readers, or
  those outside this precise subfield) are likely to have heard of ---
  the Cambridge CAP & IBM System 39.  I think the capabilities of the
  machine are not that far from CAP, but this machine has the local
  capabilities support. Is that right?

* I'd be interested in a comparison of the various capabilities here
  with  Boyland et al's "Capabilities for Sharing" - ECOOP 2001.
  I think the notion of "Ownership" is in some sense the complement of
  the local capabilities here.

* Also, the local capabilities seem related to Boyland's "Borrowing"
  e.g. that is now supported in Rust amongst other research languages
  (Pony etc) also mentioned in the ECOOP paper.

* what's going on at line 226?
Lau: fixed

* the combination of E and L capabilities seems very interesting
  indeed.  I wonder if e.g. they could be used to support strong
  models of encapsulation e.g. like ownership types. (see eg LNCS
  7850)

* I really like the idea of "private future" worlds.

* could you define "well-bracketed" ?
Lau: I think we should give this a try for our next work to be more clear about it.

* line 491 A final thing for which ... or rephrase properly

* line 515 ^5)^6 ???

* stack-clearing: would virtual memory mechanisms help?

* line 1034 scenarios
Lau: fixed

* line 1119 again see Boyland's borrowing, owner-parametric methods in
  Clarke style ownership types, etc

I have not read the 90-page appendix, nor attempted any more than a
cursory reading of the formal model in the paper.  I'm not familiar
with recent work on capability hardware such as CHERI or the
M-Machine.  This is why my review is a "medium accept". I consider my
expertise is knowledgeable due to experience on confinement and
object-capabilities generally, but not with capability hardware or the
proof techniques in this paper.

To encourage accountability, I'm signing my reviews in 2017. For the
record, I am James Noble, kjx@ecs.vuw.ac.nz.



Review #24D
===========================================================================

Overall merit
-------------
3. Weak reject - will not argue against

Reviewer expertise
------------------
Z. Outsider

Paper summary
-------------
This paper formalizes the machine language of a capability machine, and proposes a calling convention that guarantees control flow correctness. Then the paper presents a logical relation, which defines the safety of programs on the capability machine. 

Pros: 

- The capability machine seems to be an interesting application for logical relations.

Cons:

- The motivation of the work is unclear.

- Sec. 3 (calling convention) and Sec. 4 (logical relation) seem to be orthogonal. 

- There is no verification technique presented. The logical relation is simply a formalization of safety, but it’s unclear how to prove it.

- Although the paper proposes a new calling convention, there’s no implementation (e.g., compilers) and no performance evaluation. Therefore it’s unclear how practical the calling convention is.

Detailed comments:

Lau: I have inlined some comments here
- I don’t know what problems the authors try to solve. It seems the authors propose a calling convention to take advantage of the protection mechanism in the capability machine to ensure control flow correctness,
Lau: and local-state encapsulation. These are properties that are desirable in high-level languages, so it is interesting to figure out how to ensure these properties at the lowest level.
- ... and a formulation of safety for this capability machine. But what is the motivation? What are the key challenges? It’ll be nice to give some motivating examples to show what unsafe/insecure programs one can write without proper use of the capabilities, and to explain why it is difficult to formulate/verify the correctness?
Lau: I don't know what to say here, it would be interesting to demonstrate how you can write stupid programs if we wanted to write a book on capability machines, but for now we need to write a paper and hopefully reach a point where we do something more intregate than handing out capabilities left and right.
- ... The authors mention local-state encapsulation and control flow correctness in several places (e.g., line 805), but what do they mean exactly?
Lau: Again, we should try to at least formulat control-flow correctness in our future work. With respect to local-state encapsulation, I talked with Lars about the fact that this is a property that is difficult to precisely formalise.


- The logical relation is just a notion of safety or correctness for the capability machine programs. Why should this be viewed as a significant contribution? There is no verification technique provided to prove that certain programs satisfy this property. Also in what sense is this a good definition?
Lau: The notion of correctness is program specific (as can be seen from the four examples), and the logical relation do not capture the correct programs. The logical relation is merely used to prove correctness of some programs. We do not make any claim as to whether the logical relation can be used to prove all notions of correctness. With respect to safety, the logical relation captures a large class of capabilities that can safely be used as a program counter because they do not break the capability system and maintain memory protocols. We do not make any claim to whether this is the right notion of safety. However, as the examples clearly show, it is a usefull notion of safety as it can be used to show the correctness of non-trivial programs.

We believe a verification mechanism could be built on top of the logical relation (a taste of this can be seen in the technical lemma where the "scall lemma" has been extensively used. The scall lemma could be turned into a rule in a logic which could be used for program verification).

- ... Does it provides full abstraction or representation independence?
Lau: No, and we make no claim about it.
How is it connected with local-state encapsulation and control flow correctness? 

- Why do the authors propose both a new calling convention and a logical relation? They seem to be orthogonal techniques. As the paper points out, the logical relation should be regarded as an independent contribution. It would be more interesting to use the logical relation to verify correctness of compilers that implements the calling convention, but unfortunately this is left as “future work” (line 984).
Lau: The logical relation in the paper is essential to prove the correctness lemmas about the examples. The correctness of the examples depend on the encapsulation of local state as well as well-bracketed control flow which is provided by the calling convention. In other words, the logical relation is detrimental for installing some confidence in the fact that the calling convention works as claimed.


Review #24E
===========================================================================

Overall merit
-------------
3. Weak reject - will not argue against

Reviewer expertise
------------------
Y. Knowledgeable

Paper summary
-------------
This paper introduces and formalizes a technique for protecting stack data using hardware-capability mechanisms.  The paper's technique uses the CHERI system's local capabilities to give an adversary limited access to areas of a stack, ensuring that the adversary can't reuse old stack pointers to undermine security.

Hardware-based capability can potentially be used to enforce coarse-grained protection, such as protecting an application from a plugin, or fine-grained protection, such as protecting every closure and object from every other closure and object.  For coarse-grained protection, CHERI already proposed a technique to switch between stacks when crossing protection boundaries.  For fine-grained protection, managing and switching many stacks may be slow, and this paper advocates using a single stack rather than switching stacks.

Unfortunately, the paper's technique requires clearing the entire stack space between the stack pointer and the stack limit when returning to an "adversary"; in a fine-grained setting where every object method invocation is adversarial, this would be wildly expensive, even optimistically assuming some sort of hardware optimization for clearing memory.  I could imagine using OS page protection to keep stack pages inaccessible until touched, and then lazily clearing them at page-fault time, but this would still leave page-sized regions of the stack that need to be eagerly cleared.

I have some sympathy for the authors here: I think they've put their finger on a real limitation of the current CHERI "local capability" design and have done their best to make progress in spite of the hardware limitations.  But I feel like what's really needed is an ISCA paper that fixes the hardware mechanism, rather than a POPL paper that makes the best of a limited mechanism.  For example, a special stack-pointer capability mechanism could simply prohibit saving the stack pointer to the stack except as part of a call, preventing attackers from trying to stash stack pointers deep in the stack for later use.  More generally, better support in CHERI for revocable capabilities would support stacks and many other applications.  A limited amount of revocation could be made efficient with techniques like "permission lookaside buffers" (Witchel et al, ASPLOS 2002).

So I fear that the current paper is stuck in a middle ground:  it's slow under CHERI's current design, but might be moot given better hardware support for stacks and/or revocation.

All of this assumes that hardware manufacturers will actually build capability systems and that programmers will actually use them (convincing C programmers to use 256-bit pointers will be an uphill battle).  In light of recent CPU features like SGX, MPX, TrustZone, etc., it could happen.

Comments for author
-------------------
Figure 3: how is decodePermPair defined, and what is the relation between (perm', g') and (perm, g)?

page 5: incomplete sentence: "Note that the capability in the pc-register can be used to load from".

page 5: fragment: "allow literal addresses to appear as part of instructions. This means that we" % Lau: fixed

page 6: "For simplicity, we assume that memory allocated through malloc cannot be freed."  Is the expectation that malloc'd memory will be garbage collected in a real system?

page 8: "we only accept callbacks from the adversary in the form of global capabilities, which we dynamically check before invoking them".  This makes sense, but don't you also need to check arguments that are passed from the adversary to us and then passed by us into the callback?
