%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
% \acmJournal{PACMPL}
% \acmVolume{1}
% \acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
% \acmArticle{1}
% \acmYear{2018}
% \acmMonth{1}
% \acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
% \startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


% %% Some recommended packages.
% \usepackage{booktabs}   %% For formal tables:
%                         %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{wrapfig}

\usepackage{todonotes}

\input{preamble-illu}

\input{../preamble}


\begin{document}

%% Title information
\title{StackTokens: Enforcing Well-bracketed Control Flow and Stack Encapsulation using Linear Capabilities}
% \titlenote{with title note}
% \subtitle{Fully abstract overlay semantics}
% \subtitlenote{with subtitle note}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

\author{Lau Skorstengaard}
% \orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \institution{Aarhus~University}
  \country{Denmark}                    %% \country is recommended
}
\email{lask@cs.au.dk}

%% Author with two affiliations and emails.
\author{Dominique Devriese}
\orcid{0000-0002-3862-6856}             %% \orcid is optional
\affiliation{
  \institution{KU~Leuven}           %% \institution is required
  \country{Belgium}                   %% \country is recommended
}
\email{dominique.devriese@cs.kuleuven.be}         %% \email is recommended

\author{Lars Birkedal}
% \orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \institution{Aarhus~University}
  \country{Denmark}                    %% \country is recommended
}
\email{birkedal@cs.au.dk}

\begin{abstract}
  We propose and study StackTokens: a new calling convention that provably enforces well-bracketed control flow and local state encapsulation on a capability machine.
  The calling convention is based on linear capabilities, a type of capabilities that are prevented from being duplicated by the hardware.
  In addition to designing and formalising this new calling convention, we also contribute a new way to formalise and prove that it effectively enforces well-bracketed control flow and local state encapsulation, using what we call a fully abstract overlay semantics.
\end{abstract}


% %% 2012 ACM Computing Classification System (CSS) concepts
% %% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
% \begin{CCSXML}
% <ccs2012>
% <concept>
% <concept_id>10011007.10011006.10011008</concept_id>
% <concept_desc>Software and its engineering~General programming languages</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
% <concept>
% <concept_id>10003456.10003457.10003521.10003525</concept_id>
% <concept_desc>Social and professional topics~History of programming languages</concept_desc>
% <concept_significance>300</concept_significance>
% </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Software and its engineering~General programming languages}
% \ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


\keywords{fully abstract compilation, secure compilation, capability machines, linear capabilities, well-bracketed control flow, stack frame encapsulation, overlay semantics}


\maketitle


\section{Introduction}
\label{sec:introduction}
Secure compilers preserve source-language (security-relevant) properties even when the compiled code interacts with arbitrary target-language components.
Generally, properties that hold in the source language but not in the target language, need to be somehow enforced by the compiler.
Two properties that hold in many high-level source languages, but not in the assembly languages they are compiled to, are well-bracketed control flow and encapsulation of local state.

Well-bracketed control flow (WBCF) expresses that invoked functions must either return to their callers, invoke other functions themselves or diverge, and generally holds in programming languages that do not offer a primitive form of continuations. 
At the assembly level, this is not so obvious, as invoked functions get direct access to return pointers, that they are supposed to jump to a single time, at the end of their execution, but there is no guarantee that untrusted assembly code respects this intended usage.
Particularly, a function may invoke return pointers from other stack frames than its own: either frames higher in the call stack or ones that no longer exist as they have already returned before. 

Local state encapsulation (LSE) is the guarantee that when a function invokes another function, its local variables (saved on its stack frame) will not have been read or modified when the invoked function returns.
At the assembly level, this property is also far from obvious.
The calling function's local variables are stored on the stack during the invocation, and functions are not supposed to touch stack frames other than their own.
However, untrusted assembly code is free to ignore this requirement and read or overwrite the local state of other stack frames.

To enforce these properties, target language security primitives are needed that can be used to prevent untrusted code from misbehaving, without imposing too much overhead on well-behaved code.
The virtual-memory based security primitives on commodity processors do not seem sufficiently fine-grained to efficiently support this.
More suitable security primitives are offered by a type of CPUs known as capability machines \citep{levy_capability-based_1984,watson_cheri:_2015}.
These processors use tagged memory to enforce a strict separation between integers and {\itshape capabilities}: pointers that carry authority.
Capabilities come in different flavours.
Memory capabilities allow reading from and writing to a block of memory.
Additionally, capability machines offer some form of {\itshape object capabilities} that represent low-level encapsulated closures, i.e. a piece of code coupled with private state that it gains access to upon invocation.
The concrete mechanics of object capabilities varies between different capability machines.
On a recent capability machine called CHERI, for example, they take the form of pairs of capabilities sealed with a common seal that represent the code and data parts of the closure.
The pair is opaque, but is transparently unsealed by the hardware upon invocation~\citep{watson_capability_2015}.

To enforce WBCF and LSE on a capability machine, there are essentially two approaches.
A first approach uses separate stacks for distrusting components, and a central, trusted stack manager component that mediates cross-component invocations.
This idea has been applied in CheriBSD (an operating system built on CHERI)~\citep{watson_capability_2015}, but it is not without downsides.
First, it scales poorly to large amounts of distrusting components, because of the need to reserve separate stack space for all components.
Also, in the presence of higher-order values (e.g. function pointers, objects etc.), the stack manager needs to be able to decide which component a higher-order value belongs to, in order to provide it the right stack pointer upon invocation and it is not clear how this can be done efficiently in the presence of large amounts of components.
Finally, this approach does not allow passing stack references between components.

A more scalable approach retains a single stack that is shared between components.
Enforcing WBCF and LSE in this approach, requires a way to temporarily provide stack and return capabilities to an untrusted component and revoke them after it returns.
While capability revocation is expensive in general, some capability machines offer restricted forms of revocation that can be implemented efficiently.
For example, CHERI offers a form of {\itshape local} capabilities that, briefly, can only be stored in registers or on the stack, but not in other parts of memory.
\citet{skorstengaard_reasoning_2017} has demonstrated that by making the stack and return pointer local, and a number of security checks and measures, the two properties can be guaranteed.
However, a problem with this approach is that revoking the local stack and return capabilities on every boundary crossing requires clearing the entire unused part of the stack, a potentially expensive operation.

In this work, we propose and study StackTokens: an alternative calling convention that enforces WBCF and LSE with a single shared stack.
Instead of CHERI's local capabilities, it builds on {\itshape linear} capabilities; a new form of capabilities that has not been previously described in the published literature.\footnote{Although they are mentioned here and there by different people.} 
These capabilities are enforced by the hardware to be non-duplicable.
We propose to make stack and return pointers linear and require components to hand them out in cross-component invocations and to return them in returns.
The non-duplicability of linear capabilities, together with some security checks, then allows us to guarantee WBCF and LSE, without large overhead on boundary crossings and particularly no need for clearing large blocks of memory.

A second contribution of this work is the way in which we formulate these two properties, using a technique we call {\itshape fully abstract overlay semantics}.
Formulations in previous work are either partial and not suitable for reasoning~\cite{abadi_control-flow_2005} or lacked evidence of generality~\cite{skorstengaard_reasoning_2017}.
Our new formulation starts from the premise that security results for a calling convention should be reusable as part of a larger proof of a secure compiler.
To accomodate this, we define a second operational semantics for our target language, which has a native well-bracketed stack and primitive ways to do calls and returns.
This well-behaved semantics guarantees WBCF and LSE natively for components using our calling convention.
As such, these components can be sure that they will only ever interact with well-behaved other components that respect our desirable properties.
To express security of our calling convention, we then show that considering the same components in the original semantics, does not give adversaries additional ways to interact with them. 
More formally, we show that mapping a component in the well-behaved semantics to the same component in the original semantics is fully abstract~\cite{abadi_protection_1999}, i.e. that components are indistinguishable to arbitrary adversaries in the well-behaved language iff they are indistinguishable to arbitrary adversaries in the original language.

This approach expresses what it means to enforce our desirable properties, in a general way and makes it clear that we can support a very general class of programs.
Additionally, formulating security of a calling convention in this way makes it potentially reusable in a larger security proof of a full compiler.
The idea is that security of such a compiler could be verified by proving fully abstract compilation with respect to the well-behaved semantics of the target language, so that the proof can rely on native well-bracketedness and local stack frame encapsulation.
This independent result could then be composed with our result to obtain security of the compiler targeting the real target language, by transitivity of full abstraction.

\todo[inline]{Add itemized contributions}

\paragraph{Outline} Blabla

% \begin{acks}                            %% acks environment is optional
%                                         %% contents suppressed with 'anonymous'
%   %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
%   %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
%   %% acknowledge financial support and will be used by metadata
%   %% extraction tools.
%   This material is based upon work supported by the
%   \grantsponsor{GS100000001}{National Science
%     Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%   No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%   No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%   conclusions or recommendations expressed in this material are those
%   of the author and do not necessarily reflect the views of the
%   National Science Foundation.
% \end{acks}

\section{Linear Stack and Return Capabilities}
\todo[inline]{The stack grows downwards, maybe we should make the figures reflect this. Also make sealed capabilities more clear by greying out.}
\begin{figure}
  \centering
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \inactadv{(0,4)}{(4.5,7)} {\footnotesize Adv. stack frame 1}
      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted \\ \footnotesize stack frame 2}
      \actadv{(0,9)}{(4.5,12)} {\footnotesize Adv. stack frame 2}

      % Stack pointer 1
      \begin{scope}
        \clip (4.6,4) rectangle (9,13);
        \capbracebot{(4.6,4)}{(4.6,13.5)}{adv. stack\\\footnotesize cap. 1}
      \end{scope}
      Stack pointer 2
      \begin{scope}
        \clip (4.8,4) rectangle (9,13);
        \capbrace{(5.2,9)}{(5.2,13.5)}{adv. stack\\\footnotesize cap. 2}
      \end{scope}

      \draw[red,thick,->] (4.5,10) to[out=0,in=50] node[midway,right] {} (7.5,7.3);
      \draw[red,thick,->] (7,7.3) to[out=115,in=0] node[midway,right] {} (4.5,8);
    \end{tikzpicture}
    \caption{An adversary uses a previous stack frame's stack pointer.}
    \label{fig:stack-ptr-abuse}
  \end{subfigure}
  \begin{subfigure}{0.18\linewidth}
    \phantom{testtestes}
  \end{subfigure}
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \inactadv{(0,4)}{(4.5,7)} {\footnotesize Adv. stack frame 1}
      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted \\ \footnotesize stack frame 2}
      \actadv{(0,9)}{(4.5,12)} {\footnotesize Adv. stack frame 2}
      \fill[red,draw=red,opacity=.4] (-.1,3.9) rectangle (4.6,9.1);
      \draw[red,thick,->] (4.5,10.5) to[out=0,in=0] node[midway,right,align=center] {return\\ to wrong\\ return ptr} (4.5,3);
    \end{tikzpicture}
    \caption{An adversary jumps to a previous stack frame's stack pointer.}
    \label{fig:ret-ptr-abuse}
  \end{subfigure}
  
  \caption{Possible ways to abuse stack and return capabilities}
  \label{fig:stack-ret-ptr-abuse}
\end{figure}

Our StackTokens calling convention is based on a traditional single stack, shared between all components.
As we are on a capability machine, it is natural to add some extra protection to stack and return pointers.
First, we replace stack pointers with stack capabilities.
When a new stack frame is created, the caller provisions it with a stack capability, restricted to the appropriate range, i.e.\ it does not cover the caller's stack frame.
Return pointers, on the other hand, are replaced by a pair of sealed return capabilities.
They form an opaque closure that the callee can only jump to, and the caller's data becomes available to the caller's return code. 

%informally explain how an adversary may try to abuse stack and return caps
While the above adds extra protection, it is important to understand that the above is not sufficient for enforcing WBCF and LSE.
While adversaries only get access to capabilities that they are allowed to use during the stack frame, they have ways to store these capabilities and use them when they are no longer allowed to do so.
Figure~\ref{fig:stack-ret-ptr-abuse} illustrates two examples of this.
In both examples some trusted and adversarial code has been taking turns calling each other, so the stack now alternates between stack frame of the trusted and adversarial code.
The figure on the left (Figure~\ref{fig:stack-ptr-abuse}) illustrates how the trusted code tries to ensure LSE by restricting the stack capability to the unused part before every call to the adversary.
However, restricting the stack capability does not help when the trusted code in the first call gave access to the part of the stack where the stack frame of the second call now resides.
Generally speaking, the trusted code has no reason to ever trust a stack capability it receives from adversarial code as the adversarial code may have duplicated the stack capability and stored it for later use.
In the figure on the right (Figure~\ref{fig:ret-ptr-abuse}), the trusted code has given the adversarial code two sealed pairs of return capabilities, one in each of the calls to the adversarial code.
The adversarial code may have stored the pair of sealed return pointers from the first call, so that it can access it in the second call.
The figure illustrates how the adversarial code uses the return pair from the first call breaking WBCF.

% informally explain how we prevent this using linear capabilities
\lau[inline]{Write an introductory paragraph to the linear capability bit}

% What is linear capabilities, split/splice
A linear capability is a capability that cannot be duplicated.
This is enforced dynamically, so when a linear capability is moved between registers or stored to memory, the source register is cleared, and when a linear capability is read from memory, the source address is cleared.
A capability machine with linear capabilities also needs special instructions to split and splice. Split and splice do exactly what their names indicate: Split splits a capability into two capabilities with the same permissions and with ranges that are disjointed but sum up to the range of the original capability, and splice does the inverse.

% Stack capability linear
The linear capabilities are put to use by using a linear capability for the stack pointer.
When a trusted piece of code makes a call, it splits the stack capability in two, so it has a stack capability for its stack frame and one for the unused part of the stack.
The stack capability for the caller stack frame is sealed and used as the data part of the sealed return pair.
The stack capability for the remainder of the stack is given to the callee.
% Prevention of left attack non-aliasing of linear capabilities - token like (ensuring LSE)
As illustrated in Figure~\ref{fig:stack-ptr-abuse-prev}, this prevents the issue illustrated in Figure~\ref{fig:stack-ptr-abuse}.
The trusted code knows that the stack capability is linear, so when it splits the stack capability, so it has a linear capability for its local stack frame, then it also knows that this part of memory cannot have an alias.
The trusted code encapsulates the capability for its stack frame by sealing it which provides the guarantee that it can only be accessed when used with the appropriate code return pointer.

% Prevention of attack 2
In a traditional calling convention with a single stack, the stack is used as a call stack in the sense that it keeps track of the order of the calls.
If everyone follows the calling convention, then a call pushes a stack frame to the call stack and a return pops the topmost stack frame from the call stack.
This convention is not followed by the adversarial code in Figure~\ref{fig:ret-ptr-abuse} as the adversarial code skips two stack frames.
In the presence of adversarial code, we need some enforcement mechanism that forces the adversarial code to follow the call stack order.
One way to enforce this would be to hand out a token on call that can only be used when the caller's stack frame is on top of the call stack.
The callee would have to give up this token on return to make sure that the token is only spent once.
As it turns out, the stack capability for the unused part of the stack can be seen as such a token, so when the callee returns, we expect them to return the stack capability we gave them in the call.
When we receive a stack capability on return, we will try to splice it with the now unsealed stack capability for our private stack frame.
If this is successful, then we know that the two capabilities are adjacent.
If it is unsuccessful or if no stack capability is returned, then we cannot determine whether our stack frame is the topmost.
The issue illustrated in Figure~\ref{fig:ret-ptr-abuse} is prevented by splicing as illustrated in Figure~\ref{fig:ret-ptr-abuse-prev}.
\begin{figure}
  \centering
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \inactadv{(0,4)}{(4.5,7)} {\footnotesize Adv. stack frame 1}
      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted \\ \footnotesize stack frame 2}
      \actadv{(0,9)}{(4.5,12)} {\footnotesize Adv. stack frame 2}

      \lincapbrace{(4.6,2)}{(4.6,4)}{data return\\\footnotesize cap. 1}

      % Stack pointer 1
      \lincapbrace{(4.6,4)}{(4.6,7)}{adv. stack\\\footnotesize cap. 1}
      % return cap
      \lincapbrace{(4.6,7)}{(4.6,9)}{data return\\\footnotesize cap. 2}
     %  Stack pointer 2
      \begin{scope}
        \clip (4.8,4) rectangle (9,13);
        \lincapbrace{(4.6,9)}{(4.6,13.5)}{adv. stack\\\footnotesize cap. 2}
      \end{scope}

    \end{tikzpicture}
    \caption{The non-duplicable linear stack capability for the trusted code's
      stack frame and the opacity of sealed capabilities ensures LSE.}
    \label{fig:stack-ptr-abuse-prev}
  \end{subfigure}
  \begin{subfigure}{0.18\linewidth}
    \phantom{testtestes}
  \end{subfigure}
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \inactadv{(0,4)}{(4.5,7)} {\footnotesize Adv. stack frame 1}
      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted \\ \footnotesize stack frame 2}
      \actadv{(0,9)}{(4.5,12)} {\footnotesize Adv. stack frame 2}

      \lincapbrace{(4.6,2)}{(4.6,4)}{data return\\\footnotesize cap. 1}

     %  Stack pointer 2
      \begin{scope}
        \clip (4.8,4) rectangle (9,13);
        \lincapbrace{(4.6,9)}{(4.6,13.5)}{adv. stack\\\footnotesize cap. 2}
      \end{scope}

      \redcross{(5,4)}
    \end{tikzpicture}
    \caption{The trusted caller fails to splice the stack capability returned by
    the adversary with the capability for the trusted caller's local stack frame.}
    \label{fig:ret-ptr-abuse-prev}
  \end{subfigure}
  \caption{}
\end{figure}

% Non-empty trusted stack frames.
In this token-based scheme, it is important that the caller keeps a bit of the token which corresponds to having a non-empty stack frame.
In a traditional C-like calling convention, this is natural as the caller needs to push information such as the old stack pointer and the old program counter to the stack.
On a capability machine with CHERI's sealed capabilities, this is not necessary as the old program counter capability and the capability for the caller's stack frame is sealed in the return pair, and they will become unsealed when jumped to.
If the caller has an empty stack frame, then they have entirely given up all of their return token which practically means that they are not present on the call stack and thus have no way verify whether it is their turn to be returned to.

% known stack base
% + more
We check that the returned stack capability is adjacent to the stack capability for our local stack frame, but this does not guarantee that it is the same token as we gave away in the call.
Specifically, we have no idea whether the callee has kept part of the token for themselves and only given us back the part that is adjacent to our token.
If we do not make sure that the entire token is returned, then it is possible for an adversary to break WBCF.
This is illustrated in Figure~\ref{fig:stk-base-abuse}: Some trusted code has created a stack frame with their local data and called a piece of untrusted code giving them access to the remainder of the stack.
This situation is illustrated in Figure~\ref{fig:stack-base-abuse-a}.
Now the adversarial code keeps the stack capability for the part of the stack adjacent to the trusted code's stack frame.
The adversary does not seal this part in a return pair, but simply stores it on the heap.
At this point the adversary calls the trusted code with the remainder of the stack capability as illustrated in Figure~\ref{fig:stack-base-abuse-b}.
At some point the trusted code calls the adversary again leaving a second stack frame on the stack an giving the adversary the rest.
At this point, the adversary has access to the stack capability passed in the second call performed by the trusted code as well as the stack capability stored away after the first call (Figure~\ref{fig:stack-base-abuse-c}).
Now the adversary has access to a stack capability for part of the stack adjacent to the first stack frame of the trusted caller.
The adversary can use this stack capability to return from the first call without ever returning from the second call (Figure~\ref{fig:stack-base-abuse-d}).


% Where do we get the stack pointer from, how can we know it is linear
% The other attack.

% Summary of CC

\begin{figure}
  \centering
  \begin{subfigure}{0.23\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \actadv{(0,4)}{(4.5,7)}{}

      \lincapbrace{(4.6,2)}{(4.6,4)}{}
      \begin{scope}
        \clip (4.8,1) rectangle (9,13);
      \lincapbracebot{(4.6,4)}{(4.6,13.5)}{}
      \end{scope}

    \end{tikzpicture}
    \caption{}
    \label{fig:stack-base-abuse-a}
  \end{subfigure}
  \begin{subfigure}{0.24\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \inactadv{(0,4)}{(4.5,7)}{\footnotesize Kept by adv.}
      \node[opacity=0.5,rotate=-45] at (2.25,10) {\footnotesize Sent to trusted};
      \lincapbrace{(4.6,2)}{(4.6,4)}{}
      \lincapbrace{(4.6,4)}{(4.6,7)}{}
      
      \begin{scope}
        \clip (4.8,1) rectangle (9,13);
      \lincapbracebot{(4.6,7)}{(4.6,13.5)}{}
      \end{scope}

    \end{tikzpicture}
    \caption{}
    \label{fig:stack-base-abuse-b}
  \end{subfigure}
  \begin{subfigure}{0.24\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \inactsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}
      \actadv{(0,4)}{(4.5,7)}{\footnotesize Kept by adv.}
      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted\\ \footnotesize stack frame 2}
      \node[opacity=0.5,rotate=-45] at (2.25,11) {\footnotesize Returned to adv.};
      \lincapbrace{(4.6,2)}{(4.6,4)}{}
      \lincapbrace{(4.6,4)}{(4.6,7)}{}
      \lincapbrace{(4.6,7)}{(4.6,9)}{}
      \begin{scope}
        \clip (4.8,1) rectangle (9,13);
        \lincapbracebot{(4.6,9)}{(4.6,13.5)}{}
      \end{scope}

    \end{tikzpicture}
    \caption{}
    \label{fig:stack-base-abuse-c}
  \end{subfigure}
  \begin{subfigure}{0.24\linewidth}
    \centering
    \begin{tikzpicture}[scale=.5, every node={scale=.5}]
      % recurrent parts
      \stdstackstart[13]
      \actsf{(0,2)}{(4.5,4)} {\footnotesize Trusted\\ \footnotesize stack frame 1}

      \inactsf{(0,7)}{(4.5,9)} {\footnotesize Trusted\\ \footnotesize stack frame 2}
      \begin{scope}
        \clip (-.1,-.1) rectangle (4.6,13.1);
        \draw[fill=gray!50] (0,9) rectangle (4.5,13.5);
      \end{scope}

      \lincapbrace{(4.6,2)}{(4.6,7)}{}
      \lincapbrace{(4.6,7)}{(4.6,9)}{}

      \fill[red,draw=red,opacity=.4] (-.1,6.9) rectangle (4.6,9.1);
      \begin{scope}
        \clip (4.8,1) rectangle (9,13);
        \lincapbracebot{(4.6,9)}{(4.6,13.5)}{}
      \end{scope}

    \end{tikzpicture}
    \caption{}
    \label{fig:stack-base-abuse-d}
  \end{subfigure}
  \caption{}
  \label{fig:stk-base-abuse}
\end{figure}


\begin{itemize}
\item informally explain how an adversary may try to abuse stack and return caps
\item informally explain how we prevent this using linear capabilities
\item use the tikz pictures from the PriSC presentation to explain all of this
\end{itemize}

\section{A Capability Machine with Sealing and Linear Capabilities}
\label{sec:capab-mach-with}
\begin{itemize}
\item present our \emph{target language} and its operational semantics (excerpts)
\item mention roughly what components look like
\end{itemize}

\section{Formulating Security with a Fully Abstract Overlay Semantics}
\label{sec:form-secur-with}
\begin{itemize}
\item present our source language, its operational semantics (excerpts)
\item mention our assumption of reasonability
\item present the full abstraction theorem.
\end{itemize}

\section{Proving full abstraction}
\label{sec:fa-proof}

\begin{itemize}
\item Logical relation
\item FTLR
\item Sketch high-level structure of the proof
\end{itemize}

\section{Discussion}
\label{sec:discussion}
\begin{itemize}
\item mention that tail calls are supported through xjmp
\item explain how fully abstract overlay semantics could form one pass of a verified secure compiler.
\item Performance?  Implementability of linear caps?
\item Sharing stack references accross component boundaries is supported
\end{itemize}

\section{Related Work}

In this section, we discuss related work on securely enforcing control flow correctness and/or local state encapsulation.
We do not repeat the work we discussed in Section~\ref{sec:introduction}.

Capability machines originate with \citet{dennis_programming_1966} and we refer to \citet{levy_capability-based_1984} and \citet{watson_cheri:_2015} for an overview of previous work.
The capability machine formalized in Section~\ref{sec:capab-mach-with} is modeled after CHERI~\citep{watson_cheri:_2015,woodruff_cheri_2014}.
This is a recent and relatively mature capability machine, which combines capabilities with a virtual memory approach, in the interest of backwards compatibility and gradual adoption.
For simplicity, we have omitted features of CHERI that were not needed for modelling StackTokens (e.g.\ local capabilities, virtual memory).

Plenty of other papers enforce well-bracketed control flow at a low level, but most are restricted to preventing particular types of attacks and enforce only partial correctness of control flow.
This includes particularly the line of work on \emph{control-flow integrity}~\citep{abadi_control-flow_2005}.
This technique prevents certain classes of attacks by sanitizing addresses before direct and indirect jumps based on static information about a program's control graph and a shadow stack.
Contrary to StackTokens, CFI can be implemented on commodity hardware rather than capability machines.
However, its attacker model is different and its security goals are weaker.
They assume an attacker that is not able to execute code, but can overwrite arbitrary data at any time during execution (to model buffer overflows).
In terms of security goals, the technique does not enforce local stack encapsulation.
Also, it only enforces a weak form of control flow correctness, saying that jumps stay within the static control flow graph of a program~\cite{Abadi2005Theory}.
Such a property ignores temporal properties and seems hard to use for reasoning.
There is also more and more evidence that these partial security properties are not enough to prevent realistic attacks in practice~\citep{Evans:2015:CJW:2810103.2813646,Carlini2015ControlFlowBending}.

More closely related to our work are papers that use separate per-component stacks, a trusted stack manager and some form of memory isolation to enforce control-flow correctness as part of a secure compilation result~\citep{patrignani_modular_2016,juglaret_beyond_2016}.
Our work differs from theirs in that we use a different low-level security primitive (a capability machine with local capabilities rather than a machine with a primitive notion of compartments) and we do not use per-component stacks or a trusted stack manager, but a single shared stack and a decentralized calling convention based on linear capabilities.
Both prove a secure compilation result from a high-level language, which clearly implies a general form of control-flow correctness, but that result is not separated from the results about other aspects of their compiler.

CheriBSD applies a similar approach with separate per-component stacks and a trusted stack manager on a capability machine~\cite{watson_cheri:_2015}.
The authors use local capabilities to prevent components from accidentally leaking their stack pointer to other components, but there is no actual capability revocation at play.
They do not provide many details on this mechanism and it is, for example, not clear if and how they intend to deal with higher-order interfaces (C function pointers) or stack references shared accross component boundaries. 

The fact that our full abstraction result only applies to reasonable components (see Section~\ref{sec:form-secur-with}) makes it related to full abstraction results for unsafe languages.
In their study of compartmentalization primitives, \Citet{juglaret_beyond_2016} discuss the property of Secure Compartmentalizing Compilation (SCC): a variant of full abstraction that applies to unsafe source languages.
Essentially, they modify standard full abstraction so that preservation and reflection of contextual equivalence are only guaranteed for components that are {\itshape fully defined}, which means essentially that they do not exhibit undefined behavior in any fully defined context.
In follow-up work, \citet{DBLP:journals/corr/abs-1802-00588} extend this approach to scenarios where components only start to exhibit undefined behavior after a number of well-defined steps.
If we see reasonable behavior as defined behavior, then our full abstraction result can be seen as an application of this same idea.
Our results do not apply to dynamic compromise scenarios because they are intended to be used in the verification of a secure compiler, where these scenarios are not relevant.

\bibliography{references}


%% Appendix
% \appendix
% \section{Appendix}

% Text of appendix \ldots

\end{document}
 