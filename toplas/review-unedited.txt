Dear Mr. Lau Skorstengaard,

Based on the reviews, I ask that you prepare a major revision of your paper and submit it as a revision to the current manuscript.  Please be advised that while this paper does have promise, due to TOPLAS' very high standards, there is no guarantee that a revised version of the paper will be accepted.  If you have any questions on what is required, please correspond with Dr Andrew Myers and CC Ms Aubrey Cunningham aclestis@gmail.com, so we can include your correspondence in the paper trail.

Your revision consists of two parts:
1) the revised PDF that you will submit via the web site
2) a log of changes to your paper.

The reviewers are generally in agreement about your paper. It seems to be a significant technical contribution. Though there are some complaints about the delta wrt to the ESOP paper, this is not a showstopper from my perspective as long as the total improvement over the ESOP paper is sufficient. Thus, the more concerning comments from the reviewers are about the presentation, which does not seem to have been improved enough from the earlier paper. The reviewers would like to see more contextualization wrt prior work and prior technical approaches, and more justification of the technical choices and limitations incurred. There is a common theme that the technical development could be made more accessible and the text could be more polished. TOPLAS offers the opportunity to create a more accessible exposition -- this seems like a paper where the opportunity should be seized. So although one reviewer recommends rejection, my expectation is that with real effort from the authors -- which would requires more than point edits! -- this paper can really shine.

Please read over the reviews carefully, because they have a number of good suggestions. In preparing the revision, please log  the changes you have made to your paper by copying the reviewers' and associate editor's comments into the log. Under each comment, state how you have addressed whatever problems or concerns they point out. Upon submitting a revision you will be asked to enter (copy/paste) your response in a text box -- please do not upload your response as a separate document. Uploaded responses create additional delays in review response time.

Please try to provide your revision in three months or less so that the reviewers can still have your work in mind when they read the revision. If your revision will require more time, please contact the Traffic Manager directly (aclestis@gmail.com).

Best regards,
Andrew Myers
Editor in Chief, ACM TOPLAS

- - - - - - - - - -

From the reviewers:

Referee: 1

Comments to the Author
Summary:

This paper presents the formalisation of the design for a capability machine, inspired by the recent CHERI machine and the M Machine. The authors formalise the machine's instructions and their semantics. They then formalise the intuitive notion of "capability safety" (roughly that the effects a program can cause depend only on what capabilities it has access to) via a step-indexed Kripke logical relation. This allows them to prove a fundamental theorem of capability safety which becomes a foundational building block for reasoning about untrusted code (allowing one to place an upper bound on the effects it can cause). From that the authors then show how the logical relation can be used to reason precisely about small code snippets and, particularly, their (often highly complex) interactions with untrusted code. This includes proving properties like well-backed control flow.

Evaluation:

Overall this is an impressive piece of work. The contribution is likely significant. The presentation is also very good: the authors have done an admirable job of taking highly advanced meta theory and making it accessible, striking a good balance between intuitive explanations and technical details.

Where the paper falls short in its current state is in terms of contextualising the work. Specifically, one cannot tell from the current presentation to what degree the formalisation of capability safety is novel wrt recent work of Devriese et al. (EuroS&P 2016, hereafter referred to as "Devriese").

As here, Devriese also presents a logical relation formalisation of capability safety, but for a higher level language. Devriese is also a step indexed Kripke logical relation with a public/private distinction. How much of the ideas here are inspired by Devriese et al? How much were independently discovered (noting that Devriese is a co-author of this present paper), and how much is novel?

A larger meta-question, that the paper make the paper stronger if it answered, is: to what degree is the highly advanced machinery of this form of logical relation necessary for formalising capability safety? The machinery appears necessary given the basic design decisions the authors make, but might there be another set of design decisions (for the formalism, not for the capability machine) that would allow a formalisation of capability safety with simpler machinery? If so, what would be lost/gained?

Let me give an example, which I would encourage the authors to look into and to compare against. While absent from the Related Work and References of this present paper, another not-so-recent effort to formalise and prove a notion of capability safety for a quite different "capability machine" is Sewell et al.'s (ITP 2011) "seL4 Enforces Integrity".

As with the present paper, Sewell considers a capability machine, in the form of the capability-based API provided by the seL4 microkernel. They formalise bounds on authority in terms of predicates on what memory is allowed to be modified, as a function of capability possession. However they side-step the need for the sophisticated machinery of the step-indexed Kripke logical relation.

To this reviewer's understanding, the present paper requires this machinery because of circularity between capability safety and authority bounds. By this I mean that IIUC: authority bounds are allowed to depend on capability possession (which is quite natural: e.g. "memory location X cannot be modified [because nobody possesses a capability allowing that modification]"). But capability possession is also allowed to depend upon these predicates: a capability is safe so long as there exist predicates that prevent e.g. one using that capability to gain possession of other capabilities that are unsafe (see lines 770--774 of the present paper).

Sewell et al. avoid this kind of circularity by defining a separate "permission propagation" policy, defining how capabilities are allowed to propagate in the system. A "confinement" theorem  (Sewell et al. call it "authority confinement" but it would be more correct to call it "permission confinement") is proved showing that the policy is a safe upper bound for all future states when it satisfies certain well-formedness conditions. Then a separate theorem (what Sewell call "integrity enforcement" but here we would read it as an authority bound) is proved stating that all memory modifications that can be caused in the system in future states are in accordance with the authority propagation policy. The policy therefore seems to serve to cut out the circularity that would otherwise exist, since the propagation policy cannot refer to the predicates that encode the authority upper bound. [Possibly this makes Sewell et al's approach less expressive than the present one but this is exactly the kind of issue that would strengthen this paper if the authors could clarify.]

As with the authors' Fundamental Theorem, Sewell's integrity theorem also allows for reasoning about untrusted code wrt the capabilities it (might) possess (in future). The relationship between the two I believe deserves clarification.  

In summary, the paper would be strengthened by shedding light on how this formalisation of capability safety relates to that of Devriese and Sewell: the former to highlight what is novel in terms of the logical relation and the latter to highlight what the sophisticated machinery of the logical relation buys.

I'd therefore encourage the authors to strengthen the paper before publication in TOPLAS.


Referee: 2

Comments to the Author
(The paper is an extended version of a previous conference publication.  I have
compared the two versions and, to the best of my knowledge, the authors did
incorporate the additions mentioned in the introduction.)

I like the paper's approach of characterizing the security guarantees of a
capability machine using logical relations, especially how the logical relations
describe the evolution of the state of the shared stack and the use of local
capabilities to soundly encapsulate state.  The techniques build up on solid
prior work for reasoning about local state, which makes me quite confident about
their correctness.  On the other hand, the technical setup is quite involved,
making it hard to understand how each detail fits in the big picture.  Though
examples like the awkward example of Section 8 have proved difficult to handle
before, it is hard to imagine how this technique could scale up to more
realistic programs given the intricate proofs involved.  Nevertheless, the
present contributions are an important first step, and deserve to be published.

I have included various issues that should be addressed in a next revision
below.  Generally speaking, I feel that more polishing is needed in the text --
the paper does not read very well right now.

## Introduction

> It [...] can be efficient assuming only one additional piece of processor
> support: an efficient instruction for clearing a range of memory. [l86]

Not including local capabilities, I suppose.

> This paper is an extension of a published conference paper [l111]

Missing white space before citation.

> an introduction [...] that provide [l115]

"provides".  I also think that this additional introduction, while helpful, is
not substantial enough to be claimed as a standalone addition to the previous
version.

> We have added a proof sketches [l117]

"sketch"

> how one reason [l125]

"how one reasons"

## Section 3

> For simplicity, we assume that memory allocated through malloc cannot be
> freed. [l302]

In a more realistic design, how would you prevent code from misusing previously
freed memory?

## Section 4

> State × Rels corresponds to the aforementioned state transition system where
> Rels contains pairs of relations corresponding to the public and private
> transitions. [l683]

Using "states" is confusing at this point, since they could be mistaken by
machine states (that is, elements of ExecConf).  I suggest changing the name, or
at least clarifying that the two states are not the same thing.  It would
greatly improve the presentation if you gave simple examples of what you want to
represent with states.

> The different monotonicity requirements [...] reflects [l690]

"reflect"

> In the future world relations, we must remember all region names in order to
> keep them extensional which is why we need to use masks... [l723]

I could not understand this paragraph. What does it mean to keep a region
extensional? Could you give some intuition for the "technical reasons" that
require revoked regions?

(This first sentence would be clearer if you replaced "masks" by "revoked
regions.")

> It does, however, not matter [l724]

"It does not, however, matter"

> ... as those that contain safe words (i.e. words in $\mathcal{V}$).  [l757]

At this point, I had lost track of what $\mathcal{V}$ was.  Given that
$\mathcal{V}$ is defined in the following paragraph, perhaps you could remove
the parenthesis, or simply swap the two paragraphs.

I did not understand the explanation about the notation $\stackrel{n}{⫇}$
[l773]. What does it mean for $W(r)$ to accept a value? Regions contain
predicates on memory segments, and not on values.  It would be useful to remind
the reader that the formal definition is in the appendix.


> it makes use of the isomorphism of Theorem 4.1 [l780]

Mention $\xi$ in this sentence.

Using juxtaposition to express function application in l860 is a bit confusing,
given that the usual $f(x)$ syntax is used throughout the paper, even with $H$
(cf. l1037).

> An interesting property of the write condition is that they prohibit... [l877]

Who is "they"?

## Section 6

You could include Figure 12 on the top-right corner of Figure 13 to improve
readability.

It is not very clear whether the variable $ofc$ in Fig. 12 the same as the
variable $ofc$ in Fig. 13.  (I imagine it isn't, given that the offset to the
label "after" in Fig. 13 is more than five instructions long.)

> and the contents of $\bar{r_i}$ is stored [l1177]

"are stored"

## Section 7

> It is especially annoying, when ... [l1188]

Drop the comma.

Lemma 7.2 needs more explanation.  Things such as $ι^{sta}$, $revokeTemp$,
"pointing to stack", etc. need to be defined near the statement of the lemma, or
at least explained with some intuition, even when they are defined in the
appendix. I am also not sure about where some variables are quantified (e.g
$ms''$).

Explain whether the call macro used in l1327 is defined as a part of the
heap-based calling convention [l1340].

## Section 8

Maybe the awkward example of 8.2 would be easier to follow if we had the
original ML-like code for reference.

The footnote on l1446 looks strange.

> c.f. Section 3 [l1478]

"cf."

> where the stack region of $W_1$ has been revoked [l1479]

Awkward phrasing; the following sentence explains that the region was not
revoked in $W_2$, but replaced by a different one.

> standard region $ι^{pwl}$-region [l1482]

Broken sentence.

> for the part of the stack, we will provide to the callback [l1482]

Drop the comma.

> it is also important for the reasoning about x that this is a private future
> world. [l1516]

Why?

> and x is set to 0 [l1500]

Isn't x set to 1 at this point? It had already been set to 0 two paragraphs ago.

## Section 9

> Formulations in terms of a control-flow graph ... do not take into account
> temporal properties. [l1554]

Explain why.

> that our logical relation imply [l1556]

"implies"

> but it would entail some changes to the islands we use [l1590]

Replace "islands" by "regions", for consistency.

> Revoking authority ..., requires [l1603]

Drop the comma.

> use of local capabilities in ccall [l1610]

"CCall", for consistency.

I find the semantic vs. syntactic contrast discussed in l1670 ill defined.
Using your get* instructions it should be possible to test whether the range of
a capability is contained in the range of another capability, hence to encode an
assertion to test that property.  However, you first characterize range
properties as "syntactic," and later state that an assertion never failing is
"semantic" (l1688).  It would be best to avoid this classification.

## Appendix

The $\stackrel{n}{⊆}$ relation used in l1900 should be defined somewhere
earlier.

"perm" and "temp" are typeset inconsistently in l1918.


Referee: 3

Comments to the Author
Paper summary:
Capability machines are a type of processor that provides security guarantees at the hardware level. The security guarantees this paper focuses on are local encapsulation and control flow correctness. This paper presents a formalization of a capability machine that uses a new calling convention. It presents a logical relation to prove that the machine ensures local encapsulation and control flow correctness.

This paper provides an extended write-up of an ESOP 2018 paper with the same title by the same authors. The authors say that it provides minor improvements to readability and completeness (l111-l113).

High-level comments:
* While the results are worthwhile and the techniques used are interesting, but the write-up is not particularly smooth to follow. It alternates between vague high-level intuitions of why things work and between knee-deep technical details without enough introductory background to make it comprehensible. I have some reservation towards accepting the paper: although the results are worth publishing, they were already published at ESOP, and the additional parts that were added did not always particularly improve readability.

All in all, I found the paper pretty difficult to follow (often merely because of how things are formulated).

* The machine described is not particularly realistic: it uses unbounded arithmetic and assumes there is an infinite address space. The authors claim that this is to avoid uninteresting details (l137-l138). Verifying realistic models is not "uninteresting". No intuition is given on how future work can lift such assumptions. 

* Regarding the extended write-up:
The introduction to the logical relation section is helpful as well as the section providing a specification of malloc.
I found the additional figures rather confusing and the technical details that were lifted from the appendix into the paper can use more explanation. The proof sketches that were added are hard to follow and heavily refer to the technical appendix.

* Introduction:
** It would be good to expand the introduction and include a smoother introduction to the topic.
** The paragraphs include more than one main idea making them hard to follow. Consider a better split of topics.

Detailed Comments:

* l26, l26. control-flow correctness, local encapsulation, etc.
  etc. -> What other properties are programmers interested in?
  
* l55. The examples in the introduction are often unclear and need more elaboration.
  For instance, on l55, consider expanding them rather than quick mention between brackets.

* l65-l68. Hard to parse.

* l73. drop the "?"

* What's an attach-defense arm's race?
* l74, l276. What do you mean by watertight?
* l76. What does well bracketed mean?

* l84-l89. Our calling convention can be efficient assuming the processor has an instruction that can efficiently clear a range of memory.
  I doubt this a realistic assumption to be making.

* l111-l132. This part is very poorly written and needs heavy language revision.

* The explanation doesn't follow the order of the instructions in Figure 2 and some of the instructions are not explained.

* Figure 3. could you provide an intuition of why RWX <= RWLX despite L<=G.
  I would have intuitively expected the opposite.

* l159. How does your jmp instruction differ from a standard jump.

* l247. "that is then in pc": verb missing

* l253. to clear the -> of clearing the

* l246-l259. Check grammar and flow.

* l260-l265. What are the consequences of your local capability model as opposed to CHERI's? Does allowing local capabilities to be passed across module boundaries have any impact on security? If so, what impact does it have?

* l295. "a special register r_{stk}" containing a stack pointer?

* l326. "subseg instruction" this instruction is not explained.

* l336. "on the stack" missing verb

* l336. which assumption are you referring to?

* l342. "(5a)", "(5b)" -> (Figure 5a), (Figure 5b)

* l390. "(5c)" -> (Figure 5c)

* Figure 4. What is sp?
  I couldn't understand what this figure is trying to convey.

* l425. "the activation record" -> "what we call an activation record"
        it is not introduced at this point
        
* l426. "Clearly, neither of these capabilities" which two? activation record and return pointer?
         Being more explicit will make this paragraph easier to follow.

* l451. "calling convention should be combined with protection against stack smashing attacks"
        It would be nice to have a summary of these somewhere.

* l491-l501. Revise write-up.

* l514. Introduce what well-bracketed control flow means.

* l551. what are V and P? I don't believe they were introduced.

* "makes our logical relation into a Kripke logical relation"
  Some intuition or introducing what a Kripke logical relation is would be appreciated.

* l585. Still not sure what P is.

* l597. provide intuition -> provide an intuition

* l597-l621. I found this part confusing and not particularly well-formulated.

* Figure 7. What is the difference between red and green (if any)?

* I found the rest of Section 4 very hard to follow and the results hard to verify -- formal specifications and proofs would make these proofs easier to accept (I realize that this would be a lot of effort).

* Good discussion section listing limitations and directions for future work

* The references need revision: missing year (e.g., l1879), out of margin (e.g., l1841), inconsistent conventions
